<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">

<head>
	<meta http-equiv="content-type" content="text/html; charset=utf-8" />
	<meta name="description" content="Shunsuke Saito&#39;s Homepage" />
	<meta name="keywords" content="Shunsuke Saito, 齋藤 隼介, 斉藤 隼介, 斎藤 隼介, USC, University of Southern California, PIFu" />
	<meta name="author" content="Shunsuke Saito, 齋藤 隼介, 斉藤 隼介, 斎藤 隼介" />
	<link href='http://fonts.googleapis.com/css?family=PT+Sans+Narrow:400,700' rel='stylesheet' type='text/css'>
	<link type="text/css" rel="stylesheet" href="style.css?v=12345" media="screen" />
	<script src="//code.jquery.com/jquery-1.9.1.js"></script>
	<title>Shunsuke Saito / 齋藤 隼介 - Reality Labs Research</title>
</head>

<body>
	<div id="mainwrap">

		<header>
			<h1><a target="_blank" rel="noopener noreferrer" href="/">Shunsuke Saito</a></h1>
			<h2>Reality Labs Research</h2>
			<ul id="menu">
				<li><a class="profile" href="#profile" title="Profile">Profile</a></li>
				<li><a class="publication" href="#publication" title="Publication">Publication</a></li>
				<li><a class="contact" href="#contact" title="Contact">Miscellaneous</a></li>
			</ul>
		</header>
		<div style="clear:both"></div>
		<div id="content">
			<div id="profile" class="section">
				<div class="column col3">
					<table id="bioinfo">
						<tbody>
							<tr>
								<td class="odd">Name</td>
								<td class="even">Shunsuke Saito (齋藤 隼介)</td>
							</tr>
							<tr>
								<td class="odd">Interest</td>
								<td class="even">Human digitization algorithms that work in practice</td>
							</tr>
							<tr>
								<td class="odd">Email</td>
								<td class="even">{firstname}.{lastname}16 (at) gmail.com</td>
							</tr>
						</tbody>
					</table>
					<ul class="social">
						<li><a target="_blank" rel="noopener noreferrer"
								href="https://scholar.google.co.jp/citations?hl=en&user=IolN_okAAAAJ"
								class="external"><img src="img/icons/gscholar.png" alt="Google Scholar" /></a></li>
						<li><a target="_blank" rel="noopener noreferrer" href="https://github.com/shunsukesaito"
								class="external"><img src="img/icons/github.png" alt="GitHub" /></a></li>
						<li><a target="_blank" rel="noopener noreferrer" href="https://twitter.com/psyth91"
								class="external"><img src="img/icons/twitter.png" alt="Twitter" /></a></li>
						<li><a target="_blank" rel="noopener noreferrer" href="http://www.linkedin.com/in/shunsukesaito"
								class="external"><img src="img/icons/linkedin.png" alt="Linkedin" /></a></li>
					</ul>
				</div>
				<div class="column col5 pl-20">
					<p><img class="migi" src="img/Shunsuke.jpg" alt="Shunsuke Saito" height="180" align="right" /></p>
					<p> I am a Research Scientist at Reality Labs Research in Pittsburgh, where I lead the effort on next
						generation digital humans (<a target="_blank" rel="noopener noreferrer"
						href="https://about.meta.com/realitylabs/codecavatars/sapiens/">foundational model</a>, <a target="_blank" rel="noopener noreferrer"
						href="https://shunsukesaito.github.io/rgca/">relighting</a>, <a target="_blank" rel="noopener noreferrer"
						href="https://markomih.github.io/KeypointNeRF/">faces</a>, <a target="_blank" rel="noopener noreferrer"
						href="https://frozenburning.github.io/projects/urhand/">hands</a>, <a target="_blank" rel="noopener noreferrer"
						href="https://mks0601.github.io/ExAvatar/">full-body</a>, <a target="_blank" rel="noopener noreferrer"
						href="https://yuefanshen.net/CTHair">hair</a>, <a target="_blank" rel="noopener noreferrer"
						href="https://www-users.cse.umn.edu/~guo00109/projects/3dv2024/">clothing</a>,
						<a target="_blank" rel="noopener noreferrer"
						href="https://junxuan-li.github.io/megane/">accessories</a>, and more!). For example, I am one of the core
						contributers of <a target="_blank" rel="noopener noreferrer"
							href="https://youtu.be/hvfV-iGwYX8?t=4646">Codec
							Avatar 2.0</a>, which was featured in <a target="_blank" rel="noopener noreferrer"
							href="https://youtu.be/hvfV-iGwYX8?t=4646">Meta Connect 2022</a> and <a target="_blank"
							rel="noopener noreferrer" href="https://youtu.be/MVYrJJNdrEg?si=Iagizz2LT5FTPWnR">Lex
							Fridman's metaverse interview with MZ</a>.
						If you are interested in an internship with us, feel free to email/DM me!
					</p>
				</div>
			</div>

			<div id="publication" class="section">
				<table id="cv">
					<tbody>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div>
										<a target="_blank" rel="noopener noreferrer"
											href="https://about.meta.com/realitylabs/codecavatars/sapiens/"><img class="content-image"
												src="img/sapiens.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>
													Human-centric vision foundational model with 1k resolution support!
												</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://about.meta.com/realitylabs/codecavatars/sapiens/">Sapiens: Foundation for Human Vision Models</a><br />
									ECCV 2024 (Oral)
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2408.12569"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									<!-- &nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://taeksuu.github.io/ncho/static/videos/project_page_video.mp4"><img
											src="img/youtube.gif" width="16" height="16" title="Video"></a> -->
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://about.meta.com/realitylabs/codecavatars/sapiens/">[Project (code, results)]</a>
									<br />
									Rawal Khirodkar, Timur Bagautdinov, Julieta Martinez, Su Zhaoen, Austin James, Peter Selednik, Stuart Anderson, Shunsuke Saito<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div>
										<a target="_blank" rel="noopener noreferrer"
											href="https://shahrukhathar.github.io/2024/07/22/Bridging.html"><img class="content-image"
												src="img/bridge.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>
													Studio-quality avatar generation just from a phone scan by *bridging* the gap!
												</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://shahrukhathar.github.io/2024/07/22/Bridging.html">Bridging the Gap: Studio-like Avatar Creation from a Monocular Phone Capture</a><br />
									ECCV 2024 (Oral)
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2407.19593"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									<!-- &nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://taeksuu.github.io/ncho/static/videos/project_page_video.mp4"><img
											src="img/youtube.gif" width="16" height="16" title="Video"></a> -->
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://shahrukhathar.github.io/2024/07/22/Bridging.html">[Project (video)]</a>
									<br />
									ShahRukh Athar, Shunsuke Saito, Zhengyu Yang, Stanislav Pidhorsky, Chen Cao<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div>
										<a target="_blank" rel="noopener noreferrer"
											href="https://mks0601.github.io/ExAvatar/"><img class="content-image"
												src="img/exavatar.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>
													Expressive body/hand/face Gaussian avatar just from a single video!
												</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://mks0601.github.io/ExAvatar/">Expressive Whole-Body 3D Gaussian Avatar</a><br />
									ECCV 2024
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2407.21686"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://www.youtube.com/watch?v=GzXlAK-sBKY"><img
											src="img/youtube.gif" width="16" height="16" title="Video"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://mks0601.github.io/ExAvatar/">[Project (video, code)]</a>
									<br />
									Gyeongsik Moon, Takaaki Shiratori, <strong>Shunsuke Saito</strong>
									<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div>
										<a target="_blank" rel="noopener noreferrer"
											href="https://shunsukesaito.github.io/rgca/"><img class="content-image"
												src="img/highcloth.png" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>
													Synthesizing high-fidelity wrinkles from a coarse mesh with diffusion models!
												</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://shunsukesaito.github.io/rgca/">High-Fidelity Modeling of Generalizable Wrinkle Deformation</a><br />
									ECCV 2024
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2312.03704.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									<!-- &nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://taeksuu.github.io/ncho/static/videos/project_page_video.mp4"><img
											src="img/youtube.gif" width="16" height="16" title="Video"></a> -->
									<!-- &nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://shunsukesaito.github.io/rgca/">[Project (video, demo)]</a> -->
									<br />
									Jingfan Guo, Jae Shin Yoon, Shunsuke Saito, Takaaki Shiratori, Hyun Soo Park<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div>
										<a target="_blank" rel="noopener noreferrer"
											href="https://shunsukesaito.github.io/rgca/"><img class="content-image"
												src="img/rgca.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>
													See video for high-quality details and *all-frequency* reflections
													under any illuminations!
												</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://shunsukesaito.github.io/rgca/">Relightable Gaussian Codec
										Avatars</a><br />
									CVPR 2024 (Oral)
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2312.03704.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									<!-- &nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://taeksuu.github.io/ncho/static/videos/project_page_video.mp4"><img
											src="img/youtube.gif" width="16" height="16" title="Video"></a> -->
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://shunsukesaito.github.io/rgca/">[Project (video, code, data)]</a>
									<br />
									Shunsuke Saito, Gabriel Schwartz, Tomas Simon, Junxuan Li, Giljoo Nam<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div>
										<a target="_blank" rel="noopener noreferrer"
											href="https://frozenburning.github.io/projects/urhand/"><img
												class="content-image" src="img/urhand.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>
													Spatially varying linear model for universal relightable hand
													prior!
												</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://frozenburning.github.io/projects/urhand/">URHand: Universal
										Relightable Hands</a><br />
									CVPR 2024 (Oral)
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2401.05334.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									<!-- &nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://taeksuu.github.io/ncho/static/videos/project_page_video.mp4"><img
											src="img/youtube.gif" width="16" height="16" title="Video"></a> -->
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://frozenburning.github.io/projects/urhand/">[Project (video)]</a>
									<br />
									Zhaoxi Chen, Gyeongsik Moon, Kaiwen Guo, Chen Cao, Stanislav Pidhorskyi, Tomas
									Simon, Rohan Joshi, Yuan Dong, Yichen Xu, Bernardo Pires, He Wen, Lucas Evans, Bo
									Peng, Julia Buffalini, Autumn Trimble, Kevyn McPhail, Melissa Schoeller, Shoou-I Yu,
									Javier Romero, Michael Zollhöfer, Yaser Sheikh, Ziwei Liu*, Shunsuke Saito*<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div>
										<a target="_blank" rel="noopener noreferrer"
											href="https://snuvclab.github.io/gala/"><img class="content-image"
												src="img/gala.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>
													Pose-guided SDS for decomposing a single mesh into animatable
													layered
													assets!
												</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://snuvclab.github.io/gala/">GALA: Generating Animatable Layered
										Assets
										from a Single Scan</a><br />
									CVPR 2024
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2401.12979.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://snuvclab.github.io/gala/static/videos/project_page_video.mp4"><img
											src="img/youtube.gif" width="16" height="16" title="Video"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://snuvclab.github.io/gala/">[Project (video,
										code)]</a>
									<br />
									Taeksoo Kim*, Byungjun Kim*, Shunsuke Saito, Hanbyul Joo<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div>
										<a target="_blank" rel="noopener noreferrer"
											href="https://jyunlee.github.io/projects/interhandgen/"><img class="content-image"
												src="img/interhandgen.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>
													Unified two-hand interaction prior with a novel cascaded diffusion!
												</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description">
									<a target="_blank" rel="noopener noreferrer"
										href="https://jyunlee.github.io/projects/interhandgen/">InterHandGen: Two-Hand Interaction
										Generation via Cascaded Reverse Diffusion</a><br />
									CVPR 2024
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2403.17422.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://jyunlee.github.io/projects/interhandgen/">[Project (video,
										code)]</a>
									<br />
									Jihyun Lee, Shunsuke Saito, Giljoo Nam, Minhyuk Sung, Tae-Kyun Kim<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div>
										<a target="_blank" rel="noopener noreferrer"
											href="https://zielon.github.io/d3ga/"><img class="content-image"
												src="img/dega.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>
													Drivable and articulated 4D Gaussian Splatting of Avatars!
												</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://zielon.github.io/d3ga/">Drivable 3D Gaussian Avatars</a><br />
									Preprint
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2311.08581.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									<!-- &nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://taeksuu.github.io/ncho/static/videos/project_page_video.mp4"><img
											src="img/youtube.gif" width="16" height="16" title="Video"></a> -->
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://zielon.github.io/d3ga/">[Project (video)]</a>
									<br />
									Wojciech Zielonka, Timur Bagautdinov, Shunsuke Saito, Michael Zollhöfer, Justus
									Thies, Javier Romero<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div>
										<a target="_blank" rel="noopener noreferrer"
											href="https://www-users.cse.umn.edu/~guo00109/projects/3dv2024/"><img
												class="content-image" src="img/diffcloth.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>
													Diffusion prior for wrinkle-accurate cloth registration!
												</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://www-users.cse.umn.edu/~guo00109/projects/3dv2024/">Diffusion Shape
										Prior for Wrinkle-Accurate Cloth Registration</a><br />
									3DV 2024
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2311.05828.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									<!-- &nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://taeksuu.github.io/ncho/static/videos/project_page_video.mp4"><img
											src="img/youtube.gif" width="16" height="16" title="Video"></a> -->
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://www-users.cse.umn.edu/~guo00109/projects/3dv2024/">[Project (code
										coming soon)]</a>
									<br />
									Jingfan Guo, Fabian Prada, Donglai Xiang, Javier Romero, Chenglei Wu, Hyun Soo Park,
									Takaaki Shiratori, Shunsuke Saito<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div>
										<a target="_blank" rel="noopener noreferrer"
											href="https://mks0601.github.io/ReInterHand/"><img class="content-image"
												src="img/reinterhand.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>
													<a target="_blank" rel="noopener noreferrer"
														href="https://sh8.io/#/relightable_hands">RelightableHands
													</a> can be useful <br />for boosting monocular two-hand estimation!
												</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://mks0601.github.io/ReInterHand/">A Dataset of Relighted 3D
										Interacting
										Hands</a><br />
									NeruIPS 2023 (Datasets and Benchmark Track)
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2310.17768.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									<!-- &nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://taeksuu.github.io/ncho/static/videos/project_page_video.mp4"><img
											src="img/youtube.gif" width="16" height="16" title="Video"></a> -->
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://mks0601.github.io/ReInterHand/">[Project (code, data)]</a>
									<br />
									Gyeongsik Moon, <strong>Shunsuke
										Saito</strong>, Weipeng Xu, Rohan Joshi, Julia Buffalini, Harley Bellan,
									Nicholas Rosen, Jesse
									Richardson, Mallorie Mize, Philippe de Bree, Tomas Simon, Bo Peng, Shubham Garg,
									Kevyn McPhail,
									Takaaki Shiratori<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div>
										<a target="_blank" rel="noopener noreferrer"
											href="https://vcai.mpi-inf.mpg.de/projects/2023-DPE/"><img
												class="content-image" src="img/dpe.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Diffusion prior for high-quality illumination estimation via inverse
													rendering!
												</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://vcai.mpi-inf.mpg.de/projects/2023-DPE/">Diffusion Posterior
										Illumination for
										Ambiguity-aware
										Inverse Rendering</a><br />
									ACM Transaction on Graphics (SIGGRAPH Asia 2023)
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://vcai.mpi-inf.mpg.de/projects/2023-DPE/papers/main_paper.pdf"><img
											src="img/icon_pdf.gif" width="16" height="16" title="Full Text"></a>
									<!-- &nbsp;<a target="_blank" rel="noopener noreferrer"
							href="https://taeksuu.github.io/ncho/static/videos/project_page_video.mp4"><img
								src="img/youtube.gif" width="16" height="16" title="Video"></a> -->
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://vcai.mpi-inf.mpg.de/projects/2023-DPE/">[Project (video,
										code)]</a>
									<br />
									Linjie Lyu, Ayush Tewari, Marc Habermann, <strong>Shunsuke
										Saito</strong>, Michael Zollhoefer, Thomas Leimkuehler, and Christian
									Theobalt<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div>
										<a target="_blank" rel="noopener noreferrer"
											href="https://youtu.be/IfHiGSsm7K0?si=peIeMYlPc-0VsrX4"><img
												class="content-image" src="img/sgd.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>No 3D superivision for 360˚ texturing of clothed humans!
												</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/IfHiGSsm7K0?si=peIeMYlPc-0VsrX4">Single-Image 3D Human
										Digitization with
										Shape-guided Diffusion</a><br />
									SIGGRAPH Asia 2023
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2311.09221.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/IfHiGSsm7K0?si=peIeMYlPc-0VsrX4"><img
											src="img/youtube.gif" width="16" height="16" title="Video"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://human-sgd.github.io/">[Project]</a>
									<br />
									Badour AlBahar, <strong>Shunsuke Saito</strong>, Hung-Yu Tseng, Changil Kim,
									Johannes Kopf, and Jia-Bin Huang<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div>
										<a target="_blank" rel="noopener noreferrer"
											href="https://taeksuu.github.io/ncho/"><img class="content-image"
												src="img/ncho.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Scalable 3D compositional modeling of humans and <br /> many objects!
												</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://taeksuu.github.io/ncho/">NCHO : Unsupervised Learning for Neural
										3D Composition of Humans and Objects</a><br />
									ICCV 2023
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2305.14345.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://taeksuu.github.io/ncho/static/videos/project_page_video.mp4"><img
											src="img/youtube.gif" width="16" height="16" title="Video"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://taeksuu.github.io/ncho/">[Project (video, code, data)]</a>
									<br />
									Taeksoo Kim, <strong>Shunsuke
										Saito</strong>, Hanbyul Joo<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div>
										<a target="_blank" rel="noopener noreferrer"
											href="http://yuefanshen.net/CTHair"><img class="content-image"
												src="img/ct2hair.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>See through inside hair via CT<br /> to build
													accurate and
													complete<br /> hair strands!
												</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="http://yuefanshen.net/CTHair">CT2Hair: High-Fidelity 3D Hair Modeling
										using Computed Tomography</a><br />
									ACM Transaction on Graphics (SIGGRAPH 2023)
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://dl.acm.org/doi/pdf/10.1145/3592106"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/GdvxgsITZOw"><img src="img/youtube.gif" width="16"
											height="16" title="Video"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="http://yuefanshen.net/CTHair">[Project
										(video, code, data)]</a>
									<br />
									Yuefan Shen, <strong>Shunsuke
										Saito</strong>, Ziyan Wang, Olivier Maury, Chenglei Wu, Jessica Hodgins, Youyi
									Zheng, Giljoo Nam<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div>
										<a target="_blank" rel="noopener noreferrer"
											href="https://sh8.io/#/relightable_hands"><img class="content-image"
												src="img/rehand.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Real-time rendering of relightable hands with <br />global
													illumination!
												</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://sh8.io/#/relightable_hands">RelightableHands: Efficient Neural
										Relighting of Articulated Hand Models</a><br />
									CVPR 2023
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2302.04866.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/GGt0R6vn0g8"><img src="img/youtube.gif" width="16"
											height="16" title="Video"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://sh8.io/#/relightable_hands">[Project (video)]</a>
									<br />
									Shun Iwase, <strong>Shunsuke
										Saito</strong>, Tomas Simon, Stephen Lombardi, Timur Bagautdinov, Rohan Joshi,
									Fabian Prada, Takaaki Shiratori, Yaser Sheikh, Jason Saragih<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div>
										<a target="_blank" rel="noopener noreferrer"
											href="https://junxuan-li.github.io/megane/"><img class="content-image"
												src="img/megane.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Learning compositional generative models of <br />glasses and human
													heads<br /> (bonus: relightable)!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://junxuan-li.github.io/megane/">MEGANE: Morphable Eyeglass and
										Avatar Network</a><br />
									CVPR 2023
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2302.04868.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									<!-- &nbsp;<a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=qU0q5h6IldU"><img
											src="img/youtube.gif" width="16" height="16" title="Video"></a> -->
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://junxuan-li.github.io/megane/">[Project (video)]</a>
									<br />
									Junxuan Li, <strong>Shunsuke
										Saito</strong>, Tomas Simon, Stephen Lombardi, Hongdong Li, Jason Saragih<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div>
										<a target="_blank" rel="noopener noreferrer"
											href="https://research.facebook.com/publications/dressing-avatars-deep-photorealistic-appearance-for-physically-simulated-clothing/"><img
												class="content-image" src="img/dressingavatar.gif" width="200"
												align="left">
											<div class="content-details fadeIn-bottom">
												<p>Physics-based simulation meets Neural Rendering!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://research.facebook.com/publications/dressing-avatars-deep-photorealistic-appearance-for-physically-simulated-clothing/">Dressing
										Avatars: Deep Photorealistic Appearance for Physically Simulated
										Clothing</a><br />
									ACM Transaction on Graphics (SIGGRAPH Asia 2022)
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2206.15470.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://research.facebook.com/publications/dressing-avatars-deep-photorealistic-appearance-for-physically-simulated-clothing/">[Project
										(video, supmat)]</a>
									<br />
									Donglai Xiang, Timur Bagautdinov, Tuur Stuyck, Fabian Prada, Javier Romero, Weipeng
									Xu, Shunsuke Saito, Jingfan Guo, Breannan Smith, Takaaki Shiratori, Yaser Sheikh,
									Jessica Hodgins, Chenglei Wu<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div>
										<a target="_blank" rel="noopener noreferrer"
											href="https://markomih.github.io/KeypointNeRF/"><img class="content-image"
												src="img/keynerf.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>High-res and generalizable volumetric avatar for face and body!
													(no SMPL/3DMM needed)</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://markomih.github.io/KeypointNeRF/">KeypointNeRF:
										Generalizing Image-based Volumetric Avatars using Relative Spatial Encoding of
										Keypoints</a><br />
									ECCV 2022
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2205.04992.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://www.youtube.com/watch?v=RMs1S5k9vrk"><img src="img/youtube.gif"
											width="16" height="16" title="Video"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://markomih.github.io/KeypointNeRF/">[Project (video, code)]</a>
									<br />
									Marko Mihajlovic, Aayush Bansal, Michael Zollhöfer, Siyu Tang, <strong>Shunsuke
										Saito</strong><br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div>
										<a target="_blank" rel="noopener noreferrer"
											href="https://zqbai-jeremy.github.io/autoavatar/"><img class="content-image"
												src="img/autoavatar.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Learning history-dependent dynamics from raw scans <br>
													by
													efficient autoregression <br>with neural fields!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://zqbai-jeremy.github.io/autoavatar/">AutoAvatar:
										Autoregressive Neural Fields for Dynamic Avatar Modeling</a><br />
									ECCV 2022
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2203.13817.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									<!-- &nbsp;<a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=qU0q5h6IldU"><img
											src="img/youtube.gif" width="16" height="16" title="Video"></a> -->
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://zqbai-jeremy.github.io/autoavatar/">[Project (video, code)]</a>
									<br />
									Ziqian Bai, Timur Bagautdinov, Javier Romero, Michael Zollhöfer, Ping Tan,
									<strong>Shunsuke Saito</strong><br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div>
										<a target="_blank" rel="noopener noreferrer"
											href="https://radualexandru.github.io/neural_strands/"><img
												class="content-image" src="img/neuralstrands.gif" width="200"
												align="left">
											<div class="content-details fadeIn-bottom">
												<p>Fast-rendering of photorealistic<br>
													hair via joint modeling of <br> strands and appearance!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://radualexandru.github.io/neural_strands/">Neural Strands: Learning
										Hair Geometry
										and Appearance from Multi-View Images</a><br />
									ECCV 2022
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2207.14067.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/lX-pBr9E1zw"><img src="img/youtube.gif" width="16"
											height="16" title="Video"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://radualexandru.github.io/neural_strands/">[Project (video)]</a>
									<br />
									Radu Alexandru Rosu, <strong>Shunsuke Saito</strong>, Ziyan Wang, Chenglei Wu, Sven
									Behnke, Giljoo Nam
									<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div>
										<a target="_blank" rel="noopener noreferrer"
											href="https://youtu.be/t7_TMD7v0Xs"><img class="content-image"
												src="img/sig22_cao.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Hyper-realistic animatable avatars just from <br>a quick phone scan!
												</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/t7_TMD7v0Xs">Authentic
										Volumetric Avatars From a Phone Scan</a><br />
									ACM Transaction on Graphics (SIGGRAPH 2022)
									&nbsp;<a
										href="https://drive.google.com/file/d/1i4NJKAggS82wqMamCJ1OHRGgViuyoY6R/view?usp=sharing"><img
											src="img/icon_pdf.gif" width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/t7_TMD7v0Xs"><img src="img/youtube.gif" width="16"
											height="16" title="Video"></a>
									<br />
									Chen Cao, Tomas Simon, Jin Kyu Kim, Gabe Schwartz, Michael Zollhoefer,
									<strong>Shunsuke Saito</strong>, Stephen Lombardi, Shih-en Wei, Danielle Belko,
									Shoou-i Yu, Yaser Sheikh, Jason Saragih<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div>
										<a target="_blank" rel="noopener noreferrer"
											href="https://arxiv.org/abs/2207.09774"><img class="content-image"
												src="img/sig22_dva.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Real-time drivable full-body volumetric avatars!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/abs/2207.09774">Drivable
										Volumetric Avatars Using Texel-aligned Features</a><br />
									SIGGRAPH 2022 (Conference Track)
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2207.09774.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									<!-- &nbsp;<a target="_blank" rel="noopener noreferrer" href="https://www.youtube.com/watch?v=qU0q5h6IldU"><img
											src="img/youtube.gif" width="16" height="16" title="Video"></a> -->
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://github.com/facebookresearch/dva">[Code]</a>
									<br />
									Edoardo Remelli, Timur Bagautdinov, <strong>Shunsuke Saito</strong>, Chenglei Wu,
									Tomas Simon, Shih-En Wei, Kaiwen Guo, Zhe Cao, Fabian Prada, Jason Saragih, Yaser
									Sheikh<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div>
										<a target="_blank" rel="noopener noreferrer"
											href="https://neuralbodies.github.io/COAP/"><img class="content-image"
												src="img/coap.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Implicit body model <br>as a drop-in replacement of SMPL for fast
													and robust collision handling!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://neuralbodies.github.io/COAP/">COAP:
										Compositional Articulated
										Occupancy of People</a><br />
									CVPR 2022
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2204.06184.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://www.youtube.com/watch?v=qU0q5h6IldU"><img src="img/youtube.gif"
											width="16" height="16" title="Video"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://neuralbodies.github.io/COAP/">[Project (code)]</a>
									<br />
									Marko Mihajlovic, <strong>Shunsuke Saito</strong>, Aayush Bansal, Michael
									Zollhoefer, Siyu Tang<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div>
										<a target="_blank" rel="noopener noreferrer"
											href="https://neuralfields.cs.brown.edu/"><img class="content-image"
												src="img/neuralfields.png" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Wanna know more about <br>neural fields papers? <br>Check out
													our search engine <br> and survey!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://neuralfields.cs.brown.edu/">Neural Fields in
										Visual Computing and Beyond</a><br />
									Eurographics STAR 2022
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2111.11426.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://neuralfields.cs.brown.edu/">[Search Engine]</a>
									<br />
									Yiheng Xie, Towaki Takikawa, <strong>Shunsuke Saito</strong>, Or Litany, Shiqin Yan,
									Numair Khan, Federico Tombari, James Tompkin, Vincent Sitzmann, Srinath
									Sridhar<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a target="_blank" rel="noopener noreferrer"
											href="https://youtu.be/kNtlheGLSR8"><img class="content-image"
												src="img/archpp.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Achieving SoTA performance on animatable avatar modeling by
													revisiting
													its formulation!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/kNtlheGLSR8">ARCH++:
										Animation-Ready Clothed Human Reconstruction Revisited</a><br />
									ICCV 2021
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2108.07845.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/kNtlheGLSR8"><img src="img/youtube.gif" width="16"
											height="16" title="Video"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://tonghehehe.com/archpp">[Project
										(results)]</a>
									<br />
									Tong He*, Yuanlu Xu*, <strong>Shunsuke Saito</strong>, Stefano Soatto, Tony Tung (*
									-
									equal contribution)<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a target="_blank" rel="noopener noreferrer"
											href="https://youtu.be/5YigyNvt4GE"><img class="content-image"
												src="img/avatar_relighting.png" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Enabling relighting of 3D animatable avatars with any illumination in
													real-time!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a
										href="https://sai-bi.github.io/project/sig21_avatar/index.html">Deep
										Relightable
										Appearance Models for Animatable Faces</a><br />
									SIGGRAPH 2021
									&nbsp;<a
										href="https://drive.google.com/file/d/11cj0mdPlpO6_c1rfTeGp7I7j5mu7vtYf/view?usp=sharing"><img
											src="img/icon_pdf.gif" width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/5YigyNvt4GE"><img src="img/youtube.gif" width="16"
											height="16" title="Video"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://sai-bi.github.io/project/sig21_avatar/index.html">[Project
										(video, paper)]</a>
									<br />
									Sai Bi, Stephen Lombardi*, <strong>Shunsuke Saito</strong>*, Tomas Simon, Shih-En
									Wei, Kevyn McPhail, Ravi Ramamoorthi, Yaser Sheikh, Jason Saragih (* -
									equal contribution)<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a
											href="https://scanimate.is.tue.mpg.de/"><img class="content-image"
												src="img/scanimate.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Clothed avatar with pose-driven deformation from raw scans without
													template or <br>surface registration!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://scanimate.is.tue.mpg.de/">SCANimate:
										Weakly Supervised Learning of Skinned Clothed Avatar Networks</a><br />
									CVPR 2021 (Oral Presentation)
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2104.03313.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/EeNFvmNuuog"><img src="img/youtube.gif" width="16"
											height="16" title="Video"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://scanimate.is.tue.mpg.de/">[Project (video, code)]</a>
									<br />
									<a target="_blank" rel="noopener noreferrer"
										href="http://cvpr2021.thecvf.com/node/290"><img src="img/neu.jpeg" width="16"
											height="16" title="Full Text"> CVPR Best Paper
										Nominee!!</a>
									<br />
									<strong>Shunsuke Saito</strong>, Jinlong Yang, Qianli Ma, Michael J. Black<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a
											href="https://qianlim.github.io/SCALE"><img class="content-image"
												src="img/scale.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>SCALE is a fast and expressive clothed human representation using a
													collection of patches!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://qianlim.github.io/SCALE">SCALE:
										Learning to Model Clothed 3D Humans with a Surface Codec of Articulated Local
										Elements</a><br />
									CVPR 2021
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2104.07660.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/-EvWqFCUb7U"><img src="img/youtube.gif" width="16"
											height="16" title="Video"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://qianlim.github.io/SCALE">[Project (video, code)]</a>
									<br />
									Qianli Ma, <strong>Shunsuke Saito</strong>*, Jinlong Yang*, Siyu Tang, Michael J.
									Black (* -
									equal contribution)<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a
											href="https://volumetric-avatars.github.io/"><img class="content-image"
												src="img/pva.png" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Pixel-aligned NeRF for <br>human head modeling!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://volumetric-avatars.github.io/">Pixel-Aligned
										Volumetric Avatars</a><br />
									CVPR 2021
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2101.02697.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://volumetric-avatars.github.io/">[Project (video)]</a>
									<!-- &nbsp;<a target="_blank" rel="noopener noreferrer" href=""><img src="img/youtube.gif" width="16" height="16" title="Video"></a> -->
									<br />
									Amit Raj, Michael Zollhöfer, Tomas Simon, Jason Saragih, Shunsuke Saito, James Hays,
									Stephen Lombardi<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a
											href="https://project-splinter.github.io/monoport/"><img
												class="content-image" src="img/monoport.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Real-time extension of PIFu <br> by fast surface localization!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://project-splinter.github.io/monoport/">Monocular
										Real-Time Volumetric Performance Capture</a><br />
									ECCV 2020, SIGGRAPH RTL (Best in Show Award)
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2007.13988.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://project-splinter.github.io/monoport/">[Project (video,
										code)]</a>
									<!-- &nbsp;<a target="_blank" rel="noopener noreferrer" href=""><img src="img/youtube.gif" width="16" height="16" title="Video"></a> -->
									<br />
									Ruilong Li*, Yuliang Xiu*, <strong>Shunsuke Saito</strong>, Zeng Huang, Kyle
									Olszewski, Hao Li (* - equal contribution)<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a
											href="https://shunsukesaito.github.io/PIFuHD/"><img class="content-image"
												src="img/pifuhd.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>High-fidelity clothed human reconstruction at 1k resolution!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://shunsukesaito.github.io/PIFuHD/">PIFuHD:
										Multi-Level Pixel-Aligned Implicit Function for High-Resolution 3D Human
										Digitization</a><br />
									CVPR 2020 (Oral Presentation)
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/2004.00452.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://shunsukesaito.github.io/PIFuHD/">[Project (video, code)]</a>
									<!-- &nbsp;<a target="_blank" rel="noopener noreferrer" href=""><img src="img/youtube.gif" width="16" height="16" title="Video"></a> -->
									<br />
									<strong>Shunsuke Saito</strong>, Tomas Simon, Jason Saragih, Hanbyul Joo<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a target="_blank" rel="noopener noreferrer"
											href="https://youtu.be/hFgErM01SHw"><img class="content-image"
												src="img/nips.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Learning neural implict surface without 3D supervision!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/1911.00767.pdf">Learning to Infer
										Implicit Surfaces without 3D Supervision</a><br />
									NeurIPS 2019
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/1911.00767.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/hFgErM01SHw"><img src="img/youtube.gif" width="16"
											height="16" title="Video"></a>
									<br />
									Shichen Liu, <strong>Shunsuke Saito</strong>, Weikai Chen, Hao Li<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a
											href="https://shunsukesaito.github.io/PIFu/"><img class="content-image"
												src="img/pifu.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Pixel-aligned neural implict function for high-quality 3D
													reconstruction (with texture)!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://shunsukesaito.github.io/PIFu/">PIFu:
										Pixel-Aligned Implicit Function for High-Resolution Clothed Human
										Digitization</a><br />
									ICCV 2019
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/1905.05172.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/S1FpjwKqtPs"><img src="img/youtube.gif" width="16"
											height="16" title="Video"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://shunsukesaito.github.io/PIFu/">[Project]</a>
									<!-- &nbsp;<a target="_blank" rel="noopener noreferrer" href=""><img src="img/youtube.gif" width="16" height="16" title="Video"></a> -->
									<br />
									<strong>Shunsuke Saito*</strong>, Zeng Huang*, Ryota Natsume*, Shigeo Morishima,
									Angjoo Kanazawa, Hao Li (* - equal contribution)<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a target="_blank" rel="noopener noreferrer"
											href="https://youtu.be/OwYvqHsh4OM"><img class="content-image"
												src="img/body19.png" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Single-view 3D clothed human reconstruction with texture by
													synthesizing
													silhouettes
													and back-side texture inference!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/1901.00049.pdf">SiCloPe:
										Silhouette-Based Clothed People</a><br />
									CVPR 2019 (Oral Presentation - Best Paper Finalist)
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/1901.00049.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/OwYvqHsh4OM"><img src="img/youtube.gif" width="16"
											height="16" title="Video"></a>
									&nbsp;<a
										href="http://www.hao-li.com/publications/additionalMaterials/cvpr2019additionalMaterialsA.pdf">[Supplemental]</a>
									<!-- &nbsp;<a target="_blank" rel="noopener noreferrer" href=""><img src="img/youtube.gif" width="16" height="16" title="Video"></a> -->
									<br />
									Ryota Natsume*, <strong>Shunsuke Saito*</strong>, Zeng Huang, Weikai Chen, Chongyang
									Ma, Hao Li, Shigeo Morishima (* - equal contribution)<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a target="_blank" rel="noopener noreferrer"
											href="https://youtu.be/UT2EiLG4Mrg"><img class="content-image"
												src="img/siga18hair.png" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>3D morphable hair model leveraging volumetric VAE and single-view
													hair
													reconstruction! <br>(even from stylish dogs!)</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a
										href="http://www.hao-li.com/publications/papers/siggraphAsia2018HSUVVA.pdf">3D
										Hair Synthesis Using Volumetric Variational Autoencoders</a><br />
									ACM Transaction on Graphics (SIGGRAPH Asia 2018)
									&nbsp;<a
										href="http://www.hao-li.com/publications/papers/siggraphAsia2018HSUVVA.pdf"><img
											src="img/icon_pdf.gif" width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/UT2EiLG4Mrg"><img src="img/youtube.gif" width="16"
											height="16" title="Video"></a>
									<br />
									<strong>Shunsuke Saito</strong>, Liwen Hu, Chongyang Ma, Hikaru Ibayashi, Linjie
									Luo, Hao Li<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a target="_blank" rel="noopener noreferrer"
											href="https://youtu.be/_JMx5VN1eeM"><img class="content-image"
												src="img/siga18face.png" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Expressive avatar modeling by novel expression synthesis <br> with
													GANs!
												</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a
										href="http://www.hao-li.com/publications/papers/siggraphAsia2018PAGAN.pdf">paGAN:
										Real-time Avatars Using Dynamic Textures</a><br />
									ACM Transaction on Graphics (SIGGRAPH Asia 2018)
									&nbsp;<a
										href="http://www.hao-li.com/publications/papers/siggraphAsia2018PAGAN.pdf"><img
											src="img/icon_pdf.gif" width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/_JMx5VN1eeM"><img src="img/youtube.gif" width="16"
											height="16" title="Video"></a>
									<br />
									Koki Nagano, Jaewoo Seo, Jun Xing, Lingyu Wei, Zimo Li, <strong>Shunsuke
										Saito</strong>, Aviral Agarwal, Jens Fursund, Hao Li<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a
											href="https://www.youtube.com/watch?v=khNWYKfZwjQ"><img
												class="content-image" src="img/sig18.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Single-view reconstruction of high-quality skin <br>reflectance
													and
													geometry!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a
										href="http://www.hao-li.com/publications/papers/siggraph2018HFFRGIFUI.pdf">High-Fidelity
										Facial Reflectance and Geometry Inference From an Unconstrained Image</a><br />
									ACM Transaction on Graphics (SIGGRAPH 2018)
									&nbsp;<a
										href="http://www.hao-li.com/publications/papers/siggraph2018HFFRGIFUI.pdf"><img
											src="img/icon_pdf.gif" width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://www.youtube.com/watch?v=khNWYKfZwjQ"><img src="img/youtube.gif"
											width="16" height="16" title="Video"></a>
									<br />
									Shugo Yamaguchi*, <strong>Shunsuke Saito*</strong>, Koki Nagano, Yajie Zhao, Weikai
									Chen, Kyle Olszewski, Shigeo Morishima, Hao Li (* - equal contribution)<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a
											href="http://www.hao-li.com/publications/papers/cvpr2018MFGIDNN.pdf"><img
												class="content-image" src="img/cvpr18.png" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Modeling meso-scale facial geometry using image-to-image translation
													in
													UV space!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a
										href="http://www.hao-li.com/publications/papers/cvpr2018MFGIDNN.pdf">Mesoscopic
										Facial Geometry inference Using Deep Neural Networks</a><br />
									CVPR 2018 (Spotlight Presentation)
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="http://www.hao-li.com/publications/papers/cvpr2018MFGIDNN.pdf"><img
											src="img/icon_pdf.gif" width="16" height="16" title="Full Text"></a>
									<br />
									Loc Huynh, Weikai Chen, Shunsuke Saito, Jun Xing, Koki Nagano, Andrew Jones, Hao Li,
									Paul Debevec<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a target="_blank" rel="noopener noreferrer"
											href="https://youtu.be/dERjpAaoNjk"><img class="content-image"
												src="img/siga17.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Complete head avatar reconstruction from a single photograph!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a
										href="http://www.hao-li.com/publications/papers/siggraphAsia2017ADFSIFRTR.pdf">Avatar
										Digitization from a Single Image for Real-Time Rendering</a><br />
									ACM Transaction on Graphics (SIGGRAPH Asia 2017)
									&nbsp;<a
										href="http://www.hao-li.com/publications/papers/siggraphAsia2017ADFSIFRTR.pdf"><img
											src="img/icon_pdf.gif" width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/dERjpAaoNjk"><img src="img/youtube.gif" width="16"
											height="16" title="Video"></a>
									<br />
									Liwen Hu*, <strong>Shunsuke Saito*</strong>, Lingyu Wei*, Koki Nagano, Jaewoo Seo,
									Iman Sadeghi, Jens Fursund, Yen-Chun Chen, Hao Li (* - equal contribution)<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><img class="content-image"
											src="img/narita17.gif" width="200" align="left">
										<div class="content-details fadeIn-bottom">
											<p>Fabrication-ready <br>garment transfer from <br>human to animals!</p>
										</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a
										href="https://drive.google.com/open?id=1X22k5VH3rTti_ajX5pgsDtqQR2hbYROA">Quasi-Developable
										Garment Transfer for Animals</a><br />
									SIGGRAPH ASIA 2017 Technical Brief
									&nbsp;<a
										href="https://drive.google.com/open?id=1X22k5VH3rTti_ajX5pgsDtqQR2hbYROA"><img
											src="img/icon_pdf.gif" width="16" height="16" title="Full Text"></a>
									<br />
									Fumiya Narita, <strong>Shunsuke Saito</strong>, Tsukasa Fukusato, Shigeo
									Morishima<br>
								</p>
							</td>
						</tr>


						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a target="_blank" rel="noopener noreferrer"
											href="https://youtu.be/Jeg8eGr2CCc"><img class="content-image"
												src="img/vrst17.png" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Fast and robust 6 DOF <br>estimation of headsets!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a
										href="https://drive.google.com/open?id=1jxla2EBx4B_yEKkK3loIwhMVFduZrDZe">Outside-in
										Monocular IR Camera based HMD Pose Estimation via Geometric
										Optimization</a><br />
									VRST 2017
									&nbsp;<a
										href="https://drive.google.com/open?id=1jxla2EBx4B_yEKkK3loIwhMVFduZrDZe"><img
											src="img/icon_pdf.gif" width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/Jeg8eGr2CCc"><img src="img/youtube.gif" width="16"
											height="16" title="Video"></a>
									<br />
									Pavel A. Savkin, <strong>Shunsuke Saito</strong>, Jarich Vansteenberge, Tsukasa
									Fukusato, Lochlainn Wilson, Shigeo Morishima<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a target="_blank" rel="noopener noreferrer"
											href="https://youtu.be/jpAijE0X57w"><img class="content-image"
												src="img/denseface.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Dense correspondences <br>on faces in the wild!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a
										href="http://www.hao-li.com/publications/papers/iccv2017LDFCUI.pdf">Learning
										Dense Facial Correspondences in Unconstrained Images</a><br />
									ICCV 2017
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="http://www.hao-li.com/publications/papers/iccv2017LDFCUI.pdf"><img
											src="img/icon_pdf.gif" width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/jpAijE0X57w"><img src="img/youtube.gif" width="16"
											height="16" title="Video"></a>
									<br />
									Ronald Yu, <strong>Shunsuke Saito</strong>, Haoxiang Li, Duygu Ceylan, Hao Li<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a target="_blank" rel="noopener noreferrer"
											href="https://youtu.be/R-kkq4xxVNw"><img class="content-image"
												src="img/dynaTex.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Novel expression synthesis of faces in the wild using GANs!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a
										href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Olszewski_Realistic_Dynamic_Facial_ICCV_2017_paper.pdf">Realistic
										Dynamic Facial Textures From a Single Image Using GANs</a><br />
									ICCV 2017
									&nbsp;<a
										href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Olszewski_Realistic_Dynamic_Facial_ICCV_2017_paper.pdf"><img
											src="img/icon_pdf.gif" width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/R-kkq4xxVNw"><img src="img/youtube.gif" width="16"
											height="16" title="Video"></a>
									<br />
									Kyle Olszewski*, Zimo Li*, Chao Yang*, Yi Zhou, Ronald Yu, Zeng Huang, Sitao Xiang,
									Shunsuke Saito, Pushmeet Kohli, Hao Li (* - equal contribution)<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a target="_blank" rel="noopener noreferrer"
											href="https://youtu.be/VtttfrmfMZw"><img class="content-image"
												src="img/sca17.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>High-quality facial performance capture with deep learning!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/1609.06536.pdf">Production-Level
										Facial Performance Capture Using Deep Convolutional Neural Networks</a><br />
									SCA 2017
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/1609.06536.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/VtttfrmfMZw"><img src="img/youtube.gif" width="16"
											height="16" title="Video"></a>
									<br />
									Samuli Laine, Tero Karras, Timo Aila, Antti Herva, <strong>Shunsuke Saito</strong>,
									Ronald Yu, Hao Li, Jaakko Lehtinen<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a target="_blank" rel="noopener noreferrer"
											href="https://youtu.be/qX8AIRsFmTA"><img class="content-image"
												src="img/phototex.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Representing skin details as high-dimentional "style" using style
													transfer for photoreal
													avatar from a single image!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/1612.00523v1.pdf">Photorealistic
										Facial Texture Inference Using Deep Neural Networks</a><br />
									CVPR 2017 (Spotlight Presentation)
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://arxiv.org/pdf/1612.00523v1.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/qX8AIRsFmTA"><img src="img/youtube.gif" width="16"
											height="16" title="Video"></a>
									<br />
									<strong>Shunsuke Saito*</strong>, Lingyu Wei*, Liwen Hu, Koki Nagano, Hao Li (* -
									equal contribution)<br />
									<a title="https://www.fxguide.com/featured/face-me-part-1-photorealistic-facial-texture-from-a-single-still/"
										href="https://www.fxguide.com/featured/face-me-part-1-photorealistic-facial-texture-from-a-single-still/">featured
										in fx guide</a>, <a
										title="http://gizmodo.com/neural-networks-can-now-turn-a-single-photo-into-a-cree-1789786327"
										href="http://gizmodo.com/neural-networks-can-now-turn-a-single-photo-into-a-cree-1789786327">Gizmodo</a>,
									<a title="http://www.dailymail.co.uk/sciencetech/article-4011606/Avatar-breakthrough-AI-create-perfect-3D-face-single-picture-revealed-ve-tried-Donald-Trump-Hillary-Clinton-Muhammad-Ali.html"
										href="http://www.dailymail.co.uk/sciencetech/article-4011606/Avatar-breakthrough-AI-create-perfect-3D-face-single-picture-revealed-ve-tried-Donald-Trump-Hillary-Clinton-Muhammad-Ali.html">Daily
										Mail</a>, <a title="http://shiropen.com/2016/12/05/21760"
										href="http://shiropen.com/2016/12/05/21760">Seamless</a>, <a
										title="http://www.3ders.org/articles/20161208-researchers-turn-2d-photos-into-eerily-lifelike-3d-face-models-using-neural-networks.html"
										href="http://www.3ders.org/articles/20161208-researchers-turn-2d-photos-into-eerily-lifelike-3d-face-models-using-neural-networks.html">3ders</a>,
									and <a
										title="https://www.wired.de/collection/tech/dieses-neuronale-netz-erschafft-3d-gesichter-aus-unscharfen-fotos"
										href="https://www.wired.de/collection/tech/dieses-neuronale-netz-erschafft-3d-gesichter-aus-unscharfen-fotos">Wired</a><br>
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a target="_blank" rel="noopener noreferrer"
											href="https://youtu.be/EFGhuceHJVU"><img class="content-image"
												src="img/eg17.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Simplifying production-level facial performance capture
													<br>leveraging a
													template
													model!
												</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="http://vgl.ict.usc.edu/Research/XimeaRiver/">Multi-View
										Stereo on Consistent Face Topology</a><br />
									Eurographics 2017
									&nbsp;<a
										href="http://vgl.ict.usc.edu/Research/XimeaRiver/XimeaRiver_EG_2017.pdf"><img
											src="img/icon_pdf.gif" width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/EFGhuceHJVU"><img src="img/youtube.gif" width="16"
											height="16" title="Video"></a>
									<br />
									Graham Fyffe, Koki Nagano, Loc Huynh, <strong>Shunsuke Saito</strong>, Jay Bush,
									Andrew Jones, Hao Li, Paul Debevec<br />
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a target="_blank" rel="noopener noreferrer"
											href="https://youtu.be/eOjzC_NPCv8"><img class="content-image"
												src="img/kylu.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Real-time facial performance capture from HMD cameras using neural
													nets!
												</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a
										href="http://www.hao-li.com/publications/papers/siggraphAsia2016HFFSAVH.pdf">High-Fidelity
										Facial and Speech Animation for VR HMDs</a><br />
									ACM Transaction on Graphics (SIGGRAPH Asia 2016)
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="bibtex/olszewski2016high.bib"><img src="img/icon_bib.gif" width="16"
											height="16" title="Bibtex"></a>

									&nbsp;<a
										href="http://www.hao-li.com/publications/papers/siggraphAsia2016HFFSAVH.pdf"><img
											src="img/icon_pdf.gif" width="16" height="16" title="Full Text"></a>

									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/eOjzC_NPCv8"><img src="img/youtube.gif" width="16"
											height="16" title="Video"></a>
									<br />
									Kyle Olszewski, Joseph J. Lim, <strong>Shunsuke Saito</strong>, Hao Li<br>
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a target="_blank" rel="noopener noreferrer"
											href="https://youtu.be/hPksv1gJet4"><img class="content-image"
												src="img/face.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Occlusion-aware facial performance capture <br>from a live-streaming
													video! <br>(also real-time face swapping)</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="http://arxiv.org/pdf/1604.02647v1.pdf">Real-Time Facial
										Segmentation and Performance Capture from RGB Input</a><br />
									ECCV 2016
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="bibtex/saito2016realtime.bib"><img src="img/icon_bib.gif" width="16"
											height="16" title="Bibtex"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="http://arxiv.org/pdf/1604.02647v1.pdf"><img src="img/icon_pdf.gif"
											width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/hPksv1gJet4"><img src="img/youtube.gif" width="16"
											height="16" title="Video"></a>
									&nbsp;<a
										href="https://drive.google.com/file/d/0B0J5iCVLyQO9UlhfbEhtOW54cTQ/view?usp=sharing&resourcekey=0-jRRtTN586BTaGnVH6T8zWQ">[Data]</a>
									<br />
									<strong>Shunsuke Saito</strong>, Tianye Li, Hao Li<br>
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a target="_blank" rel="noopener noreferrer"
											href="https://youtu.be/-tCUG5zllNo"><img class="content-image"
												src="img/cloth_trans.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Garment transfer from <br>human to animals!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a
										href="https://drive.google.com/open?id=1CtnLL1QdJyFfxQbXLnx3Ps8M8jKgaOhJ">Garment
										Transfer for Quadruped Characters</a><br />
									Eurographics 2016, short paper
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="bibtex/narita16garment.bib"><img src="img/icon_bib.gif" width="16"
											height="16" title="Bibtex"></a>
									&nbsp;<a
										href="https://drive.google.com/open?id=1CtnLL1QdJyFfxQbXLnx3Ps8M8jKgaOhJ"><img
											src="img/icon_pdf.gif" width="16" height="16" title="Full Text"></a>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/-tCUG5zllNo"><img src="img/youtube.gif" width="16"
											height="16" title="Video"></a><br />
									Fumiya Narita, <strong>Shunsuke Saito</strong>, Takuya Kato, Tsukasa Fukusato,
									Shigeo Morishima<br>
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a
											href="https://www.youtube.com/watch?v=1Rw1rlB866k"><img
												class="content-image" src="img/muscle.gif" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Wanna bulk up in metaverse? Interactive body shape modeling inspired
													by
													bio-physics!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a
										href="https://drive.google.com/open?id=1jGJdBG6FZzCXgnluvi6Lx_rHbnCexCpg">Computational
										Bodybuilding: Anatomically-based Modeling of Human Bodies</a> <br />
									ACM Transaction on Graphics (SIGGRAPH 2015)
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="bibtex/saito15computational.bib"><img src="img/icon_bib.gif" width="16"
											height="16" title="Bibtex"></a>

									&nbsp;<a
										href="https://drive.google.com/open?id=1jGJdBG6FZzCXgnluvi6Lx_rHbnCexCpg"><img
											src="img/icon_pdf.gif" width="16" height="16" title="Full Text"></a>

									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://www.youtube.com/watch?v=1Rw1rlB866k"><img src="img/youtube.gif"
											width="16" height="16" title="Video"></a> <br />
									<strong>Shunsuke Saito</strong>, Zi-Ye Zhou, Ladislav Kavan<br>
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a target="_blank" rel="noopener noreferrer"
											href="./patchmove/index.html"><img class="content-image"
												src="img/patchmove.png" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Efficient and robust frame interpolation by extending PatchMatch!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a target="_blank" rel="noopener noreferrer"
										href="./patchmove/index.html">PatchMove: Patch-based Fast
										Image Interpolation with Greedy Bidirectional Correspondence</a><br />
									Pacific Graphics 2014, short paper
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="bibtex/saito14patch.bib"><img src="img/icon_bib.gif" width="16"
											height="16" title="Bibtex"></a>

									&nbsp;<a target="_blank" rel="noopener noreferrer" href="./pg_patchmove.pdf"><img
											src="img/icon_pdf.gif" width="16" height="16" title="Full Text"></a>

									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://www.youtube.com/watch?v=wrUwrUdRqBo"><img src="img/youtube.gif"
											width="16" height="16" title="Video"></a> <br />

									<strong>Shunsuke Saito</strong>, Ryuuki Sakamoto, Shigeo Morishima<br>
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a
											href="http://onlinelibrary.wiley.com/doi/10.1002/cav.1589/abstract"><img
												class="content-image" src="img/homocloth.png" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Extending homogenization FEM analysis to cloth simulation!</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a
										href="http://onlinelibrary.wiley.com/doi/10.1002/cav.1589/abstract"><b>Macroscopic
											and Microscopic Deformation Coupling in Up-sampled Cloth Simulation</b></a>
									<br />
									Computer Animation and Virtual Worlds Journal (CASA 2014)
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="http://onlinelibrary.wiley.com/doi/10.1002/cav.1589/pdf"><img
											src="img/icon_pdf.gif" width="16" height="16" title="Full Text"></a>

									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://youtu.be/ETE7UVEcnRA"><img src="img/youtube.gif" width="16"
											height="16" title="Video" /></a><br>

									<strong>Shunsuke Saito</strong>, Nobuyuki Umetani, Shigeo Morishima<br>
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><a
											href="http://wscg.zcu.cz/wscg2014/Full%5CJ59-full.pdf"><img
												class="content-image" src="img/charatrans.png" width="200" align="left">
											<div class="content-details fadeIn-bottom">
												<p>Better representing character-specific expression for <br>facial
													retargeting!
												</p>
											</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description"><a
										href="http://wscg.zcu.cz/wscg2014/Full%5CJ59-full.pdf"><b>Character
											Transfer:
											Example-based individuality retargeting for facial animations</b></a> <br />
									International Conference in Central Europe on Computer Graphics, Visualization and
									Computer Vision 2014 (WSCG 2014)
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="http://wscg.zcu.cz/wscg2014/Full%5CJ59-full.pdf"><img
											src="img/icon_pdf.gif" width="16" height="16" title="Full Text"></a>

									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://www.youtube.com/watch?v=uwA-x0GeNhQ"><img src="img/youtube.gif"
											width="16" height="16" title="Video"></a><br>

									Takuya Kato, <strong>Shunsuke Saito</strong>, Masahide Kawai, Tomoyori Iwao, Akinobu
									Maejima, Shigeo Morishima<br>
								</p>
							</td>
						</tr>
						<tr>
							<td class="col2">
								<div class="container">
									<div id="teaser" class="content">
										<div class="content-overlay"></div><img class="content-image"
											src="img/cloth_esti.png" width="200" align="left">
										<div class="content-details fadeIn-bottom">
											<p>Estimating material parameters of cloth from 4D scans!</p>
										</div>
										</a>
									</div>
								</div>
								<br>
							</td>
							<td class="col6 pl-30">
								<p class="description">Estimating Cloth Simulation Parameter from 3D Cloth Motion
									Separating Dynamic from Static Motion <br />
									<i>ACM SIGGRAPH EuroGraphics Symposium on Computer Animation (SCA 2012), poster</i>
									&nbsp;<a target="_blank" rel="noopener noreferrer"
										href="https://www.youtube.com/watch?v=oEFNaTQ75yQ"><img src="img/youtube.gif"
											width="16" height="16" title="Video"></a><br>

									<strong>Shunsuke Saito</strong>, Ryusuke Sagawa, Naoya Iwamoto, Shigeo Morishima<br>
								</p>
							</td>
						</tr>
					</tbody>
				</table>

			</div>

			<div id="contact" class="section">
				<div class="column col3">
					<h3>Shunsuke Saito</h3>
					<p>Web: www-scf.usc.edu/~saitos/<br />
						E-mail: shunsuke.saito16 (at) gmail.com</p>
				</div>
				<div class="column col5 pl-50">
					<h3>Technical Paper Reviewer:</h3>
					<p>ECCV, ICCV, IJCV, SIGGRAPH, CVPR, TPAMI, ToG, AAAI, WACV, 3DV, ACCV, TVCG, Signal Processing,
						SIGGRAPH
						ASIA, CGF, PG, Eurographics, etc.</p>
					<h3>Internship:</h3>
					<p>MPI Tübingen (2020), FAIR, Adobe Research (2019), Pinscreen (2018), FRL (2017), FOVE (2015),
						Yahoo! Japan (2012-13)</p>
					<h3>Talk:</h3>
					<p><a target="_blank" rel="noopener noreferrer"
							href="https://www.ri.cmu.edu/event/digital-human-modeling-with-light/">CMU VASC Seminar</a>,
						Brown VC Seminar, <a target="_blank" rel="noopener noreferrer"
							href="https://www.birs.ca/events/2023/5-day-workshops/23w5153">BIRS Workshop</a>, <a
							target="_blank" rel="noopener noreferrer"
							href="https://www.asiagraphics.org/webinar/#session22">Asiagraphics Webinar</a> (2023), <a
							target="_blank" rel="noopener noreferrer"
							href="https://www.dagstuhl.de/en/seminars/seminar-calendar/seminar-details/22121">Dagstuhl
							Seminar</a> (2022), MPI Saarbruecken/Tuebingen, Industrial Light & Magic, <a target="_blank"
							rel="noopener noreferrer"
							href="https://www.dagstuhl.de/en/seminars/seminar-calendar/seminar-details/19102">Dagstuhl
							Seminar</a> (2019), University of
						Tokyo, CMU Graphics Group, VC Symposium (2018), VC/GCAD Symposium, Autodesk Research (2015)</p>
					<h3>Scholarship and Awards:</h3>
					<p>Outstanding Reviewer (<a target="_blank" rel="noopener noreferrer"
							href="https://twitter.com/ICCVConference/status/1707400996228378992">ICCV2023</a>, <a
							target="_blank" rel="noopener noreferrer"
							href="http://3dv2020.dgcv.nii.ac.jp/program-committee.html">3DV2020</a>,
						<a target="_blank" rel="noopener noreferrer"
							href="https://accv2020.github.io/programs/awards/index.html">ACCV2020</a>), <br>
						CVPR Best Paper Finalist (2019, 2021),<br>
						<a target="_blank" rel="noopener noreferrer"
							href="http://www.meti.go.jp/english/press/2015/0618_02.html">Super Creator, IPA Exploratory
							Software (2015)</a>,<br>
						ACM Student Research Competition Semi-Finalist (2014),<br>
						MIRU Interactive Presentation Award, Okayama, Japan (2014),<br>
						<a target="_blank" rel="noopener noreferrer"
							href="https://www.csst.ucla.edu/summerprogram.htm">UCLA
							CSST Scholarship Program $9,036
							(2013)</a>,<br>
						Okuma Memorial Special Scholarship $5,000 (2011)<br>
					</p>
				</div>
			</div>
		</div>

		<div id="footer">
			&copy; 2014 Shunsuke Saito &middot; <a target="_blank" rel="noopener noreferrer"
				href="http://andreasviklund.com/templates/this-is-me-dark/">Template
				design</a> by <a target="_blank" rel="noopener noreferrer" href="http://andreasviklund.com/">Veselka
				Dobreva</a><br />
		</div>

		<script type="text/javascript">
			$(document).ready(function () {
				$(".section").not(":first").hide();
				$("ul#menu li:first").addClass("active").show();

				$("ul#menu li").click(function () {
					$("ul#menu li.active").removeClass("active");
					$(this).addClass("active");
					$(".section").slideUp();
					$($('a', this).attr("href")).slideDown('slow');

					return false;
				});

			});
		</script>
	</div>
</body>

</html>
<script>
	(function (i, s, o, g, r, a, m) {
		i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
			(i[r].q = i[r].q || []).push(arguments)
		}, i[r].l = 1 * new Date(); a = s.createElement(o),
			m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
	})(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

	ga('create', 'UA-66428408-2', 'auto');
	ga('send', 'pageview');

</script>
